{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aea4d09-f1d5-41fd-ad9b-575d3ea6d115",
   "metadata": {},
   "source": [
    "# Week-13: Classification Task in Python\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Welcome back!\n",
    "* Today, we will go over a classification example using `skicit-learn` package in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa492eb-75f3-4984-89d1-3f8dbc75c1e1",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* `Scikit-learn`, known as `sklearn`, is an open-source, robust library for machine learning in Python.\n",
    "* It is created to streamline the process of implementing machine learning and statistical models in Python.\n",
    "* The package comes with standard machine learning datasets, and you can import it without downloading them from an external website or database.\n",
    "* Since we will go over a classification example, we will be using the [`wine dataset`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) (Click it for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223e4dda-3948-42c5-a85f-cf78f2313181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7784c3c-f727-4d4f-9059-d60534adb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa967e98-158c-4c66-9884-9f1dae36d3f0",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Executing the above code returns a dictionary-like object (we just learned!) that contains data and metadata.\n",
    "    * **Metadata**: This is a terminology for data dictionary, i.e., a description of the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7937920-8ae3-4389-9b6f-92b435c5da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a Pandas dataframe\n",
    "\n",
    "\n",
    "# Add the target label (add a new column)\n",
    "\n",
    "\n",
    "# Preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c4669-c36c-4440-abda-1f44904503c8",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Before conducting any data analysis, always check the quality of the dataset with exploratory data analysis.\n",
    "* You can call `.info()` method to print out a summary of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92a6cb-135f-4c9e-b6b1-f1756f95a7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "666a1c0f-62e8-41fb-b99f-c0805b20846c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* There are 178 data samples with 14 columns including the target column (output that we would like to predict).\n",
    "* Luckily, no missing values are in our dataset from `Non-Null Count`.\n",
    "* All features are `float64` except for target column.\n",
    "* The dataset consumes 19.6 KB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff288d89-e926-4e28-a68f-af964852220a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "236003c9-dd43-46d1-a97d-73fae18cb918",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Since `target` is a categorical variable, we check the frequency and proportion using `.value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c004e86-3ebf-4f45-8726-e1e632fedc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0d8b1b-d433-4312-acfc-50efc4e66f65",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Preprocessing is important prior to applying machine learning algorithms.\n",
    "    * Check missing values, outliers, duplicates, errors, and data types.\n",
    "    * Avoid \"Garbage in, garbage out.\"\n",
    "* Machine learning models typically require numerical inputs.\n",
    "* Another practice is to standardize the input (via Z-transform) to make predictors more comparable. \n",
    "    * We do not want predictor A has a magnitude of 10000, while predictor B has a magnitude of 0.1.\n",
    "    * We can achieve the goal using `StandardScaler()` class.\n",
    "    * Each value goes through the following transformation columnwise, i.e., $x = (x - x_{mean})/x_{sd}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d2b253-5ee5-4594-9707-5004ced1dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to import standardscaler (code should be written in the beginning of the Jupyter notebook).\n",
    "# Split data into features (input) and label (output)\n",
    "\n",
    "\n",
    "# Always make a copy to avoid making changes on the raw data (when you have sufficient amount of memory).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9da298-4547-409f-9ff5-f67e1329648c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "<img src=\"figures/sklearn_flowchart_1.png\" alt=\"drawing\" width=\"900\"/>\n",
    "    \n",
    "* In this flowchart, no output data are involved. We use `.transform()` in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7eacfaa-6c63-40b9-bd42-d12ed548946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate scaler and fit on features\n",
    "\n",
    "\n",
    "# apply changes to training data\n",
    "# and update parameters (in this case, no model parameters are available, so this is optional)\n",
    "\n",
    "\n",
    "# apply changes to any data and assign it with another variable\n",
    "\n",
    "\n",
    "# view the transformed output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a459bb-862e-4c49-84c2-47aa0aff4a8e",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* As we previously mentioned, we need to have training and testing set when we perform classification tasks.\n",
    "* If rows of input data are independent of each other, we can randomly select training and testing set.\n",
    "* Sklearn package has a built-in function called `train_test_split()`.\n",
    "* We usually set 70% data to train and 30% to test. The exact ratio vary depending on the volume of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bc0777-625c-4780-adab-b7f81478d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to import train_test_split in the beginning\n",
    "\n",
    "\n",
    "# Check the splits are correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c7783-41c7-43aa-bdbb-e6284aea7f24",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Sklearn has numerous built-in classification methods. We will demonstrate a couple of methods including\n",
    "    * logistic regression\n",
    "    * support vector machine\n",
    "    * decision tree classifier\n",
    "    \n",
    "* <img src=\"figures/sklearn_flowchart_2.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "    * In this flowchart, both input and output (in the training set) are involved, so `.predict()` is used finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb40ecea-5e32-4d35-85b9-14a2db776698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniatiating the models \n",
    "# Sometimes, you need to modify the parameters inside each of the function.\n",
    "# If not, the model will use its default values.\n",
    "# write one model and the rest two are completed by students\n",
    "\n",
    "\n",
    "# Training the models \n",
    "\n",
    "\n",
    "# Making predictions with each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7134d7-885e-4352-b536-4b5340e0fc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc6d21d-9290-45a1-937e-460b36048966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can view the probability vector per measure per method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed927f6-e723-4ed2-a972-0ba05add1976",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* In our case, we will use `classification_report()` to build a text report showing main classification metrics such as `precision`, `recall`, `f1_score`, `accuracy`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b856b675-5f55-48b6-8bcf-8ffec1ab6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report (put it in the beginning)\n",
    "# Store model predictions in a dictionary\n",
    "# this makes it easier to iterate through each model\n",
    "# and print the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9de809-15bc-440f-b76d-bfdb164fbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83993ee6-7db1-441a-b46a-d21a986e3168",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "The reported averages include \n",
    "\n",
    "* (sample) average (only for multilabel classification). \n",
    "* macro average (averaging the unweighted mean per label), \n",
    "* weighted average (averaging the support-weighted mean per label).\n",
    "\n",
    "Which method performs the best?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
